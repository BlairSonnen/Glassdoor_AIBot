{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d0f262a",
   "metadata": {},
   "source": [
    "# GlassDoor Data Download, Cleanup, and CSV Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01290d4",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "Remove commented code to install dependencies, if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6009f259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install kagglehub if you need it, just comment out the next line\n",
    "# !pip install kagglehub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29defd2",
   "metadata": {},
   "source": [
    "## Download Data into Dataframe\n",
    "Download the data from Kaggle and store into a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca430746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download the Glassdoor Job Reviews dataset from Kaggle\n",
    "path = kagglehub.dataset_download(\"davidgauthier/glassdoor-job-reviews-2\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918ce429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the csv at the variable \"path\" to a pd dataframe\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "jobs_org_df = pd.read_csv(os.path.join(path, \"all_reviews.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ab9332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the cleaned dataset\n",
    "jobs_org_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8cc89d",
   "metadata": {},
   "source": [
    "## Extract Company/Firm Names\n",
    "Convert the links to the firm names into actual firm names and store into a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71e5288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract and format the firm name\n",
    "def extract_firm_name(link):\n",
    "    # Split string on slashes\n",
    "    parts = link.split(\"/\")\n",
    "    # Extract the last part of the string (the firm name)\n",
    "    firm_name = parts[-1]\n",
    "    # Split file name on dashes\n",
    "    firm_name_parts = firm_name.split(\"-\")\n",
    "    # Remove the last 2 parts (the file extension) and join the rest with spaces\n",
    "    firm_name = \" \".join(firm_name_parts[:-2])\n",
    "    # Return the formatted firm name\n",
    "    return firm_name\n",
    "\n",
    "# Test the function with different types of links    \n",
    "print(f\"Extract firm from relative path: {extract_firm_name('Reviews/Baja-Steel-and-Fence-Reviews-E5462645.htm')}\")\n",
    "print(f\"Extract firm from absolute path: {extract_firm_name('https://www.glassdoor.com/Reviews/Calgary-Flames-Reviews-E5247.htm')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2751ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data set to extract the firm name from the link\n",
    "jobs_org_df[\"firm_name\"] = jobs_org_df[\"firm_link\"].apply(extract_firm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f37fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_data_info(df):\n",
    "    # Print Unique firm names\n",
    "    print(f\"\\nUnique firm names: {df['firm_name'].unique()}\")\n",
    "    # Print the number of unique firm names\n",
    "    print(f\"\\nNumber of unique firm names: {df['firm_name'].nunique()}\")\n",
    "    # Print the number of reviews per firm\n",
    "    print(f\"\\nNumber of reviews per firm: {df['firm_name'].value_counts()}\")\n",
    "    # Get the count of total reviews\n",
    "    print(f\"\\nTotal reviews: {df['firm_name'].count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf83b627",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_data_info(jobs_org_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c79b34e",
   "metadata": {},
   "source": [
    "## Data Cleanup\n",
    "CLean up unnecessary columns, drop nulls, and only take a minimum of 1,000 reviews per company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9f1226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows where the count of the firm name is less than 1,000\n",
    "jobs_df = jobs_org_df[jobs_org_df[\"firm_name\"].map(jobs_org_df[\"firm_name\"].value_counts()) >= 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d3670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of null or NaN entries for each column\n",
    "print(f\"\\nCount of null or NaN entries for each column:\\n{jobs_df.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be22db7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's drop the columns that have almost all NULL values\n",
    "jobs_df = jobs_df.drop(columns=[\"advice\", \"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d525d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows with null or NaN entries in any column\n",
    "jobs_df = jobs_df.dropna()\n",
    "\n",
    "# Count the number of null or NaN entries for each column\n",
    "print(f\"\\nCount of null or NaN entries for each column:\\n{jobs_df.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a2f78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get counts of each unique values in the \"status\" column\n",
    "print(f\"\\nCounts of each unique value in the 'status' column:\\n{jobs_df['status'].value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b40d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows where the count of the firm name is less than 1,000 after cleaning\n",
    "jobs_df = jobs_df[jobs_df[\"firm_name\"].map(jobs_df[\"firm_name\"].value_counts()) >= 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9117c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AFTER DATA CLEANING:\")\n",
    "display_data_info(jobs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922394d8",
   "metadata": {},
   "source": [
    "## Data Cleanup - Bias Control\n",
    "Only take 1,000 reviews per company to try and reduce bias for large companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaee988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit the dataset to 1,000 random entries per company listed in the firm_name column\n",
    "jobs_max1000_df = jobs_df.groupby(\"firm_name\").apply(lambda x: x.sample(n=1000, random_state=42)).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2340c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AFTER REDUCING EACH REVIEW COUNT TO 1,000 FOR EACH COMPANY:\")\n",
    "display_data_info(jobs_max1000_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81cb7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a \"Resources\" folder in the local directory if it does not exist\n",
    "if not os.path.exists(\"Resources\"):\n",
    "    os.makedirs(\"Resources\")\n",
    "\n",
    "# Export the cleaned dataset to a CSV file\n",
    "jobs_max1000_df.to_csv(\"Resources/cleaned_glassdoor_reviews_max1000.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71c271d",
   "metadata": {},
   "source": [
    "## Further Reduce the Data to Help with Model Consumption\n",
    "Further reduce the dataset because Google Collab was having problems with the larger file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45dcdb9",
   "metadata": {},
   "source": [
    "### Chunking approach\n",
    "Save dataset into several files with a max of 250,000 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572ac480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the size of the jobs_df dataframe\n",
    "total_rows = jobs_max1000_df.shape[0]\n",
    "rows_step = 25000\n",
    "start_index = 0\n",
    "step_number = 0\n",
    "\n",
    "# Create a \"Resources\" folder in the local directory if it does not exist\n",
    "if not os.path.exists(\"Resources\"):\n",
    "    os.makedirs(\"Resources\")\n",
    "\n",
    "# Create a \"chunked\" folder in the Resources directory if it does not exist\n",
    "if not os.path.exists(\"Resources/chunked\"):\n",
    "    os.makedirs(\"Resources/chunked\")\n",
    "\n",
    "# Loop through the dataframe in chunks of 250,000 rows\n",
    "while start_index < total_rows:\n",
    "    end_index = min(start_index + rows_step, total_rows)\n",
    "    chunk_df = jobs_max1000_df.iloc[start_index:end_index]\n",
    "    \n",
    "    # Save the chunk to a CSV file\n",
    "    chunk_df.to_csv(f\"Resources/chunked/cleaned_glassdoor_reviews_max1000_{start_index}.csv\", index=False)\n",
    "    \n",
    "    # Print Progress\n",
    "    print(f\"Saved chunk {step_number} from index {start_index} to {end_index}\")\n",
    "    print(f\"Chunk {step_number} shape: {chunk_df.shape}\")\n",
    "    \n",
    "    # Update the start index for the next chunk\n",
    "    start_index += rows_step\n",
    "\n",
    "    # Increase the step number for the next file name\n",
    "    step_number += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff6d808",
   "metadata": {},
   "source": [
    "### Sample Approach\n",
    "Reduce to a random sample of 500,000 reviews and only take companies with a minimum of 500 Reviews, and reduce all review counts to 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff7d8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample of 500,000 reviews\n",
    "jobs_sample_df = jobs_df.sample(n=500000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab486d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows where the count of the firm name is less than 500\n",
    "jobs_sample_reduced_df = jobs_sample_df[jobs_sample_df[\"firm_name\"].map(jobs_sample_df[\"firm_name\"].value_counts()) >= 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7dce7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit the dataset to 500 random entries per company listed in the firm_name column\n",
    "jobs_sample_reduced_df = jobs_sample_reduced_df.groupby(\"firm_name\").apply(lambda x: x.sample(n=500, random_state=42)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259ecaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AFTER DATA REDUCTION AND A LIMIT OF 500 REVIEWS:\")\n",
    "display_data_info(jobs_sample_reduced_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5007246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a \"Resources\" folder in the local directory if it does not exist\n",
    "if not os.path.exists(\"Resources\"):\n",
    "    os.makedirs(\"Resources\")\n",
    "    \n",
    "# Export the cleaned dataset to a CSV file\n",
    "jobs_sample_reduced_df.to_csv(\"Resources/cleaned_glassdoor_reviews_reduced_max500.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
